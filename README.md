Healthcare Data Cleaning, Wrangling, and Visualization with PySpark
This repository contains a project focused on cleaning, manipulating, wrangling, and visualizing a healthcare dataset using PySpark on Databricks. The project involves preparing raw healthcare data for analysis, followed by visualizations to provide insights into the data.

Project Overview
In this project, I worked on a healthcare dataset where I performed the following tasks:

Data Cleaning:

Handling missing values.
Removing duplicates.
Standardizing data formats (e.g., dates, text fields).
Data Manipulation:

Filtering and selecting relevant columns.      
Grouping and aggregating data.
Creating new features and columns.
Data Wrangling:

Merging and joining datasets.
Handling outliers.
Restructuring the dataset to improve efficiency and clarity.
Data Visualization:

Visualizing key healthcare metrics such as patient distribution, hospital visits, and trends over time.
Using PySpark's integration with popular visualization libraries like Matplotlib and Seaborn within Databricks.
Generating bar charts, line plots, and heatmaps to highlight trends and outliers in the data.
Key Features
PySpark and Databricks: The project leverages the power of PySpark for big data processing and Databricks for a scalable, collaborative platform.
Efficient Data Processing: PySparkâ€™s parallel processing capabilities ensure that even large datasets are handled efficiently.
Comprehensive Data Preparation: From missing value imputation to advanced transformations, the data has been thoroughly prepared for future analysis.
Data Visualization: Graphical insights from the dataset are created to support data analysis and reporting.
Technologies Used
PySpark: For data cleaning, manipulation, wrangling, and some basic visualizations.
Databricks: For running and managing Spark clusters and workflows.
Jupyter Notebooks: For documenting and running code interactively within Databricks.
Matplotlib & Seaborn: For data visualizations.
